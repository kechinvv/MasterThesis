= Реализация

Создание инструмента для применения предложенного метода извлечения поведенческих моделей библиотек заключается в реализации каждой из его частей, разобранных ранее, и их связи между собой и пользователем. В данном разделе приведена общая архитектура инструмента и детали реализации его модулей, включая различные инженерные проблемы и пути их решения.  

== Общая архитектура

Реализованный инструмент может быть использован как консольное приложение или как библиотека, с помощью которой пользователь сможет реализовывать свои сценарии анализа или пользоваться отдельными её частями. Основой инструмента являются несколько пакетов:
+ analysis -- пакет, содержащий реализацию извлечения трасс с помощью статического и динамического анализа, а именно построение ICFG, points-to анализ, фаззинг и сбор точек входа в программу
+ inference -- пакет, обеспечивающий обработку трасс и восстановление из них поведенческих моделей
+ repository -- пакет, реализующий получение репозиториев и работу с ними
+ storage -- пакет, отвечающий за работу с БД
+ workflow -- пакет, связывающий все реализованные возможности между собой с помощью определенных сценариев работы

== Пакет repository

Данный пакет решает задачи поиска, получение и сборки проектов из GitHub и Maven Central Repository. Также в рамках этого пакета реализована возможность запуска тестов, имеющихся в репозитории. Рассмотрим каждую из задач подробнее.

=== Получение проектов с GitHub

Не смотря на то, что GitHub предоставляет открытый API для поиска по коду, при разработке возникли несколько проблем:
+ Поиск происходит по файлам, соответственно, сами репозитории могут повторяться. Необходимо это учитывать, чтобы не тратить лишнее время на получение и анализ уже рассмотренного ранее проекта.
+ Один поисковой запрос может найти не более 1000 результатов, что указано в документации#footnote("https://docs.github.com/en/rest/search/search?apiVersion=2022-11-28#about-search"). С учетом повторения репозиториев, этого может быть недостаточно для автоматической работы длительное время с целью изучить большое количество проектов. При этом сторонние системы поиска по коду, например SearchCode, имеют более сильные ограничения.
+ Частые запросы к API приводят к достижению secondary rate limit#footnote("https://docs.github.com/en/rest/using-the-rest-api/rate-limits-for-the-rest-api?apiVersion=2022-11-28#about-secondary-rate-limits"). При этом, основного лимита достаточно для выполнения запросов. Каким-то образом необходимо избежать введения искусственных задержек.

Для каждой из этих проблем были реализованы следующие решения:
+ Для исключения повторений следует хранить авторов и названия проанализированных репозитории в БД. Это также будет полезно для остановки и возобновлений поисковых сессий. Чтобы не обращаться каждый раз в БД для проверки репозитория на повторение, следует реализовать кэш.
+ Чтобы обойти лимит результатов поиска, реализован адаптивный фильтр по размеру файла. Способ фильтрации предлагает сам GitHub. Таким образом, мы можем задать диапазон от 0 до максимального размера файла, который нас интересует, и проходить его определенными шагами, например изначально 100 байт. Если количество результатов поиска находится между нулем и 1000, то не меняем шаг. Если количество результатов равно нулю, то мы увеличиваем шаг в два раза, а если максимальному значению -- уменьшаем шаг в два раза.
+ Во избежание secondary rate limit применяется ленивое получение репозиториев и их последовательный анализ, реализованное с помощью наследования Sequence в языке Kotlin. Каждый запрос к API возвращает набор файлов, из которых извлекаются уникальные репозитории, и до тех пор, пока все они не будут проанализированы, API использоваться не будет. Таким образом создается естественная задержка, позволяющая избегать лимита. Если он все же был достигнут (например, подряд выполнялись несколько уменьшений или увеличений размера шага), то используется sleep перед очередной попыткой запроса.

Для поиска и получения проектов с GitHub необходимо предварительно получить и указать свой токен для API в конфигурации инструмента, а на вход подать поисковой запрос и шаблон имени файла. Это необходимо, так как можно искать по импорту среди:
- .java файлов (path:\*\*\/\*.java)
- build.gradle (path:\*\*\/build.gradle)
- build.gradle.kts (path:\*\*\/build.gradle.kts или path:\*\*\/build.gradle\* для всех вариаций)
- pom.xml (path:\*\*\/pom.xml)

Для работы с удаленными GitHub репозиториями реализован класс GhRemoteRepository, позволяющий получать доступные артефакты и исходный код всего проекта:
+ Определяется наличие выпущенной версии
+ Проверяется наличие JAR файла соответствующего версии
+ Проверяется наличие исходного кода соответствующего версии
+ Если найдены, скачиваются JAR файл и архив с кодом версии, иначе выполняется клонирование с помощью git

=== Получение проектов с Maven Central

Веб-сайт Sonatype#footnote("https://central.sonatype.com/") предлагает возможность получения зависимых библиотек от выбранной. Однако публичного API для этого не предоставлено. С помощью инструментов разработчика в браузере было найдено внутреннее API, реализующее необходимую в рамках работы задачу. Способ нахождения и структура тела запроса представлена на @internal_api_struct. Чтобы исключить вероятность блокировки при использовании данного API, было направлено электронное письмо в поддержку Sonatype. В ответе говорилось, что допустимо использовать внутренний API, если нет намерений просканировать весь Maven Central, что в рамках выполняемой работы нас устраивает. 

#figure(
  image("../img/internal_api_structure.png", height: 23%),
  caption: "Поиск необходимого API"
) <internal_api_struct>

Для поиска проектов следует указать группу, название и версию библиотеки.

Получение найденных проектов осуществляется с помощью специально созданного build.gradle файла на одну зависимость, позволяющего подставлять в него библиотеку для анализа и выполнять задачу разрешения зависимостей. Таким образом происходит автоматическое получение и сборка библиотеки для анализа и всех её зависимостей. После разрешения зависимостей следует найти полученный JAR в кэше gradle и скопировать его в заданную директорию, где должны находиться анализируемые проекты.

Как уже было упомянуто в разделе, посвященному проектированию, получение исходного кода из Maven Central бессмысленно, так как он не содержит тестов, а сборка выполнена автоматически при получении проекта с помощью gradle.

=== Сборка проектов

Проекты из Maven Central собираются автоматически из-за выбранного метода их получения. Что касается проектов с GitHub, то даже при наличии JAR файла в репозитории, он может не содержать зависимости, а следовательно, он может не запуститься. Также необходима компиляция тестов, если они есть в проекте. 

Для этого требуется в первую очередь определить, какая система сборки используется в проекте. Это делается с помощью обхода файлов и поиска характерых файлов сборки: build.gradle, build.gradle.kts, pom.xml. Если ни один из файлов не обнаружен в корне проекта, то выполняется обход вложенных директорий, так как репозиторий может иметь нестандартные вложения или состоять из нескольких модулей.

Если проект использует Gradle, то вся работа с ним может быть выполнена с помощью Gradle Tooling API. В зависимости от конфигурации инструмента версия Gradle может быть установлена автоматически для каждого проекта, зафиксирована или может быть использован уже установленный на машине сборщик.

Maven не предполагает подобного API, поэтому в зависимости от конфигурации используется сборщик, к которому указан путь или из переменных окружения.

Все виды локальных репозиториев предусматривают методы сбора трасс из файлов, которые создаются в корне проекта как результат запуска инструментированного кода. Подробнее об этом в следующем подразделе.

== Пакте analysis

== Пакет storage

== Пакет inference
