= Реализация

Создание инструмента для применения предложенного метода извлечения поведенческих моделей библиотек заключается в реализации каждой из его частей, разобранных ранее, и их связи между собой и пользователем. В данном разделе приведена общая архитектура инструмента и детали реализации его модулей, а также инженерные проблемы и пути их решения.  

== Общая архитектура

Реализованный инструмент может использоваться как консольное приложение или как библиотека, с помощью которой пользователь реализует свои сценарии анализа или использует её отдельные компоненты. Основой инструмента являются несколько пакетов:
+ analysis -- пакет, содержащий реализацию извлечения трасс с помощью статического и динамического анализа, а именно построение ICFG, анализ указателей, фаззинг и сбор точек входа в программу
+ inference -- пакет, обеспечивающий обработку трасс и восстановление из них поведенческих моделей
+ repository -- пакет, реализующий получение репозиториев и работу с ними
+ storage -- пакет, отвечающий за работу с БД
+ workflow -- пакет, связывающий все реализованные возможности между собой с помощью определенных сценариев работы. Стоит отметить, что по сути пакет содержит примеры использования компонентов и не требует детального рассмотрения

== Пакет repository

Данный пакет решает задачи поиска, получения и сборки проектов из GitHub и Maven Central Repository. Также в рамках этого пакета реализована возможность запуска тестов, имеющихся в репозитории. Далее приведён разбор каждой из задач.

=== Получение проектов с GitHub

Несмотря на то, что GitHub предоставляет открытый API для поиска по коду, при разработке возникло несколько проблем:
+ Поиск происходит по файлам. Соответственно, сами репозитории могут повторяться. Необходимо это учитывать, чтобы не тратить лишнее время на получение и анализ уже рассмотренного ранее проекта
+ Один поисковой запрос может найти не более 1000 результатов, что указано в документации#footnote("https://docs.github.com/en/rest/search/search?apiVersion=2022-11-28#about-search"). С учетом повторения репозиториев, такого количества проектов может быть недостаточно для автоматической работы в течение длительного времени с целью изучения большого количества проектов. При этом сторонние системы поиска по коду, например SearchCode, имеют более сильные ограничения
+ Частые запросы к API приводят к достижению secondary rate limit#footnote("https://docs.github.com/en/rest/using-the-rest-api/rate-limits-for-the-rest-api?apiVersion=2022-11-28#about-secondary-rate-limits"). При этом, основного лимита достаточно для выполнения запросов. Каким-то образом необходимо избежать введения искусственных задержек.

Для каждой из этих проблем были реализованы следующие решения:
+ Для исключения повторений информация о репозиториях хранится в БД. Это также будет полезно для остановок и возобновлений поисковых сессий
+ Чтобы обойти лимит результатов поиска, реализован адаптивный фильтр по размеру файла. Способ фильтрации предлагает сам GitHub. Таким образом, мы можем задать диапазон от 0 до максимального размера файла, который нас интересует, и проходить его определенными шагами, например, изначально 100 байт. Если количество результатов поиска находится между нулем и 1000, то не меняем шаг. Если количество результатов равно нулю, то мы увеличиваем шаг в два раза, а если максимальному значению -- уменьшаем шаг в два раза
+ Во избежание secondary rate limit применяется ленивое получение репозиториев и их последовательный анализ, реализованное с помощью наследования Sequence в языке Kotlin. Каждый запрос к API возвращает набор файлов, из которых извлекаются уникальные репозитории, и до тех пор, пока все они не будут проанализированы, API не используется. Таким образом создаётся естественная задержка, позволяющая избегать лимита. Если он всё же был достигнут (например, подряд выполнялись несколько уменьшений или увеличений размера шага), то используется искусственная задержка перед очередной попыткой запроса

Для поиска и получения проектов с GitHub необходимо предварительно получить и указать свой токен для API в конфигурации инструмента, а на вход подать поисковой запрос и шаблон имени файла. Это необходимо, так как можно искать по импорту среди:
- .java файлов (path:\*\*\/\*.java)
- build.gradle (path:\*\*\/build.gradle)
- build.gradle.kts (path:\*\*\/build.gradle.kts или path:\*\*\/build.gradle\* для всех вариаций)
- pom.xml (path:\*\*\/pom.xml)

Для работы с удаленными GitHub репозиториями реализован класс GhRemoteRepository, позволяющий получать доступные артефакты и исходный код всего проекта:
+ Определяется наличие выпущенной версии
+ Проверяется наличие JAR-файла соответствующей версии
+ Проверяется наличие исходного кода соответствующей версии
+ Если найдены, скачиваются JAR-файл и архив с кодом версии, иначе выполняется клонирование с помощью git

=== Получение проектов с Maven Central

Веб-сайт Sonatype#footnote("https://central.sonatype.com/") предлагает возможность получения библиотек, зависящих от выбранной. Однако публичный API для этого не предоставлен. С помощью инструментов разработчика в браузере было найден внутренний API, решающий необходимую в работе задачу. Способ нахождения и структура тела запроса представлены на #ref(<internal_api_struct>, supplement: "рисунке"). Чтобы исключить вероятность блокировки при использовании данного API, было направлено электронное письмо в поддержку Sonatype. В ответе говорилось, что допустимо использовать внутренний API, если нет намерения просканировать весь Maven Central, что приемлемо в рамках выполняемой работы. 

#figure(
  image("../img/internal_api_structure.png", height: 23%),
  caption: "Поиск необходимого API"
) <internal_api_struct>

Для поиска проектов следует указать группу, название и версию библиотеки.

Получение найденных проектов осуществляется с помощью специально созданного файла build.gradle на одну зависимость, позволяющего подставлять в него библиотеку для анализа и выполнять задачу разрешения зависимостей. Таким образом происходит автоматическое получение и сборка библиотеки для анализа и всех её зависимостей в заданную директорию.

Как уже было упомянуто в разделе, посвящённом проектированию, получение исходного кода из Maven Central бессмысленно, так как он не содержит тестов, а сборка выполнена автоматически при получении проекта с помощью Gradle.

=== Сборка проектов <building_prj>

Проекты из Maven Central собираются автоматически из-за выбранного метода их получения. Что касается проектов с GitHub, то даже при наличии JAR-файла в репозитории, он может не содержать зависимости, а следовательно, он может не запуститься. Также необходима компиляция тестов, если они есть в проекте. 

Для этого требуется в первую очередь определить, какая система сборки используется в проекте. Это делается с помощью обхода файлов и поиска характерных файлов сборки: build.gradle, build.gradle.kts, pom.xml. Если ни один из файлов не обнаружен в корне проекта, то выполняется обход вложенных директорий, так как репозиторий может иметь нестандартные вложения или состоять из нескольких модулей.

Если проект использует Gradle, то вся работа с ним может быть выполнена с помощью Gradle Tooling API. В зависимости от конфигурации инструмента версия Gradle может быть установлена автоматически для каждого проекта, зафиксирована или может быть использован уже установленный на машине сборщик.

Maven не предполагает подобного API, поэтому в зависимости от конфигурации используется сборщик, путь к которому указан явно или берётся из переменных окружения.

Класс локальных репозиториев предусматривает методы сбора трасс из файлов, которые создаются в корне проекта в результате запуска инструментированного кода.

== Пакет analysis

Данный пакет содержит реализацию статического анализа, инструментацию и запуск фаззинга, в совокупности предоставляя возможности для извлечения трасс вызовов библиотеки с применением статических и динамических подходов.

=== Сбор точек входа в программу

Как для статического извлечения трасс, так и для фаззинга необходимо предварительно получить возможные точки входа в программу. Помимо метода main, это могут быть:
- Обработчики событий. Например, методы, отвечающие за обработку запросов
- Конструкторы
- Конкретные известные пользователю методы

Чтобы иметь гибкость в вопросе выбора входных точек в программу, реализован механизм фильтрации для методов. Фильтры пишутся в формате YAML, в процессе работы инструмента десериализуются и используются для определения входных точек при анализе методов программы. Фильтр содержит следующие поля:
+ methodAnnotation -- множество аннотаций метода, доступных в runtime
+ methodName -- регулярное выражение для названия метода
+ classAnnotation -- множество аннотаций класса, доступных в runtime
+ className -- регулярное выражение для названия класса
+ kind -- вид точки входа: метод, конструктор (init) или статический инициализатор (clinit)
+ args -- список типов аргументов метода в их оригинальном порядке
+ returnType -- возвращаемый тип
+ methodModifiers -- модификаторы для метода: static, public, protected, private, final, synchronized, native
+ classModifiers -- модификаторы для класса: static, public, protected, private, final, synchronized, enum

Если значение равно null, то параметр фильтра игнорируется. Пример фильтра для поиска публичных методов с названием, начинающимся на main, принимающих массив строк, приведен в #ref(<filter_entry_example>, supplement: "листинге"). 

#figure(
  ```yaml
methodAnnotations: ["API"]
methodName: "main.*"
classAnnotations: null
className: null
kind: "method"
returnType: null
args: ["java.lang.String[]"]
methodModifiers: ["public"]
classModifiers: null
```,
caption: "Пример фильтра в yaml формате"
) <filter_entry_example>

=== Статическое извлечение трасс

Извлечение трасс с применением статического анализа состоит из нескольких основных шагов:
+ Получить точки входа в программу. Эта задача подробно разобрана чуть выше.
+ Построить ICFG. Решается с использованием стандартного API Soot, однако построение межпроцедурного графа потока управления требует запуска Soot в режиме "whole-program".
+ Выполнить обход ICFG для каждой точки входа, собирая вызовы и группируя их посредством применения анализа указателей к объектам. Рассмотрим данную задачу отдельно, так как она требует разработки определенного алгоритма обхода.

Для обхода ICFG и выполнения всех необходимых для извлечения трассы действий следует реализовать SceneTransformer и добавить его в PackageManager. Именно созданный SceneTransformer будет определять проводимый анализ.

ICFG представляет собой все возможные пути выполнения программы и, очевидно, в среднем содержит множество циклов и ветвлений. Так как нас интересуют именно трассы исполнения, их длина может быть бесконечной и её следует ограничивать. Для этого были введены два параметра:
- Глубина обхода. Изначально устанавливается некоторое число, которое уменьшается каждый раз, когда мы уходим в реализацию вызова. Когда глубина равна 0, обход не может попасть в реализацию какого-либо вызова в рассматриваемом методе и обязан пройти его до конца. Возвращаясь на уровень выше, глубина инкрементируется.
- Длина. Задаёт лимит по количеству вершин графа при обходе.

Извлечение трасс из ICFG представляет собой рекурсивный обход в глубину. Псевдокод алгоритма приведен в #ref(<graph_traverse_alg>, supplement: "листинге"). Каждое ветвление имеет собственный набор трасс, при этом оно содержит общую часть с трассами, которые будут собраны для других веток (имеются в виду ветки в одной и той же точке программы). Для того, чтобы не копировать наборы трасс, в методе фиксируется, какие трассы были дополнены на данной итерации. В конце каждого метода, после выполнения рекурсивных вызовов, с помощью сохраненных индексов трассы приводятся в свое изначальное состояние, которое было до ветвления. Сами трассы сохраняются в БД по достижению ограничений на обход или обходу всей программы. Для реализации обхода в глубину в специальном стеке сохраняется точка в программе, к которой необходимо вернуться после рассмотрения вызываемого метода до конца. Когда вызываемый метод рассмотрен, точка возврата снимается со стека.

Для поиска вызовов конкретной библиотеки выполняется сравнение с указанным префиксом названий пакетов. При обнаружении вызова применяется анализ указателей для объекта вызова и объектов из уже накопленных трасс, чтобы получить множества переменных, которые могут указывать на тот же объект. Если полученные множества пересекаются, то переменные могут указывать на один и тот же объект, и вызов помещается в соответствующую трассу, иначе создаётся новая. Таким образом, через points-to-анализ выражается alias-анализ.

При обходе перебираются все возможные в рамках наложенных ограничений по длине и глубине комбинации ветвлений. Благодаря этому удаётся достичь высокого покрытия кода и сбора содержательных трасс вызовов. Собранные трассы представляют собой последовательность из объектов класса MethodData. Пример можно увидеть в #ref(<dynamic_trace_example>, supplement: "листинге") как часть динамически получаемой трассы.

#figure(
  ```fun graphTraverseLib(
        startPoint: Unit,
        isMainMethod: Boolean,
        ttl: Int = configuration.traversJumps,
        depth: Int = configuration.traversDepth
    ) {
        val currentSuccessors = icfg.getSuccsOf(startPoint)
        if (currentSuccessors.size == 0 || ttl <= 0) {
            if (ttl <= 0 || isMainMethod) {
                save(extracted)
            } else {
                val succInfo = continueStack.removeLast()
                graphTraverseLib(succInfo.first, succInfo.second, ttl - 1, depth + 1)
                continueStack.add(succInfo)
            }
        } else {
            for (succ in currentSuccessors) {
                var method: SootMethod? = null
                var continueAdded = false
                var klass: String? = null
                var indexesOfChangedTraces: List<Int>? = null
                    if (succ is JInvokeStmt || succ is JAssignStmt) {
                        succ as AbstractStmt
                        if (succ.invokeExpr.method.declaringClass in Scene.v().applicationClasses)
                            method = succ.invokeExpr.method
                        if (method?.foundLib(lib)) {
                            klass = method.declaringClass.toString()
                            if (extracted[klass] == null) extracted[klass] = mutableListOf()
                            indexesOfChangedTraces = saveInvokeToTrace(succ.invokeExpr, extracted[klass])
                        }
                    }
                if (method != null && depth > 0) {
                    continueAdded = continueStack.add(Pair(succ, isMainMethod))
                    icfg.getStartPointsOf(method).forEach { methodStart ->
                        graphTraverseLib(methodStart, false, ttl - 1, depth - 1)
                    }
                } else graphTraverseLib(succ, isMainMethod, ttl - 1, depth)

                if (indexesOfChangedTraces != null) resetTraces(indexesOfChangedTraces, extracted[klass])
                if (continueAdded) continueStack.removeLast()
            }
        }
    }```,
  caption: "Псевдокод алгоритма обхода"
) <graph_traverse_alg>


=== Динамическое извлечение трасс

Динамическое извлечение трасс в первую очередь требует инструментации. Она реализована с помощью создания собственного SceneTransformer в Soot и заключается во вставке кода после вызовов библиотеки. Вызовы библиотеки определяются тем же способом, что и при статическом анализе. Вставленный код собирает следующие данные:
+ Identity hash code объекта вызова
+ Время вызова в наносекундах
+ UUID запуска
+ Название метода
+ Аргументы 
+ Возвращаемый тип
+ Класс метода

Для инструментации реализован вспомогательный класс, отвечающий за запись собранной информации в файл, который подкладывается в JAR. Файлы создаются для каждого потока, чтобы избежать конфликтов при многопоточной работе. UUID необходим, чтобы различать попытки запуска и исключить совпадение identity hash code в рамках разных рабочих сессий. Записи в файле представляют собой сериализованные объекты InvokeData и MethodData, которые успешно десериализуются при сборе трасс и группируются по identity hash code и UUID.

Soot при инструментации JAR-файла теряет директорию META-INF, влияющую на его запуск. Несмотря на то, что тесты не используют JAR, а фаззинг требует на вход путь к конкретному методу, это учтено и реализован механизм сохранения изначальной мета-информации и добавления её в инструментированный JAR. Это полезно для пользовательских экспериментов по извлечению трасс, позволяя сохранять JAR действительно исполняемым. 

Для получения трасс необходимо выполнить запуск тестов или фаззинг. Для запуска тестов используется Gradle Tooling API или предустановленный Maven тем же образом, который описан в @building_prj. При вызове задачи явно исключается сборка проекта, чтобы не потерять результаты инструментирования.

Для фаззинга автоматически при первом запуске происходит получение архива с исполняемыми файлами Jazzer под целевую операционную систему (в дальнейшем проверяется наличие исполняемых файлов). Фаззер вызывается как сторонний процесс для каждой точки входа и имеет следующие опции:
- -runs=N. Количество запусков указанного метода, где N -- пользовательский параметр. Если N = 0, то ограничение отсутствует
- -max_total_time=N. Длительность работы фаззера в секундах, где N -- пользовательский параметр. Для бесконечной работы опция не указывается
- \-\-keep_going=0. Игнорирует найденные фаззером ошибки. Эта опция нужна, так как мы заинтересованы в трассах, а не в тестировании программы. На самом деле вместо нуля можно указать любое другое число, означающее количество игнорируемых ошибок
- \-\-autofuzz=qualified.reference.to.Class::method. Указывает цель для фаззинга

Пример получаемой трассы для поиска вызовов класса java.io.File приведен в #ref(<dynamic_trace_example>, supplement: "листинге").

#figure(
  ```txt
{"methodData":{"name":"<init>","args":["java.lang.String"],"returnType":"void","isStatic":false,"klass":"java.io.File"},
"iHash":"443942537","date":"170309763...","uuid":"6b4..."}
{"methodData":{"name":"<init>","args":["java.lang.String"],"returnType":"void","isStatic":false,"klass":"java.io.File"},
"iHash":"1243171897","date":"170309805...","uuid":"6b4..."}
{"methodData":{"name":"exists","args":[],"returnType":"boolean","isStatic":false,"klass":"java.io.File"},
"iHash":"1243171897","date":"170309805...","uuid":"6b4..."}
{"methodData":{"name":"createNewFile","args":[],"returnType":"boolean","isStatic":false,"klass":"java.io.File"},
"iHash":"1243171897","date":"170309806...","uuid":"6b4..."}
{"methodData":{"name":"toPath","args":[],"returnType":"java.nio.file.Path","isStatic":false,"klass":"java.io.File"},
"iHash":"1243171897","date":"170309807...","uuid":"6b4..."}
{"methodData":{"name":"<init>","args":["java.lang.String"],"returnType":"void","isStatic":false,"klass":"java.io.File"},
"iHash":"1376151044","date":"170309807...","uuid":"6b4..."}
{"methodData":{"name":"delete","args":[],"returnType":"boolean","isStatic":false,"klass":"java.io.File"},
"iHash":"1376151044","date":"170309809...","uuid":"6b4..."}
{"methodData":{"name":"createNewFile","args":[],"returnType":"boolean","isStatic":false,"klass":"java.io.File"},
"iHash":"1243171897","date":"170309809...","uuid":"6b4..."}
```,
  caption: "Пример получаемой трассы"
) <dynamic_trace_example>


== Пакет storage

Для хранения результатов поиска проекта и извлечения из них трасс использована база данных SQLite. Так как это локальная БД, она позволяет легко создавать переносимые хранилища в виде файла для различных запусков инструмента. Это позволяет в дальнейшем использовать их как отправную точку для поиска репозиториев, дополнять уже накопленные трассы, проводить эксперименты по восстановлению с разными параметрами и обмениваться накопленными данными. Также она не требует специального окружения и может создаваться с использованием соответствующей библиотеки. Работа с БД реализована с помощью ktorm.

БД состоит из двух таблиц:
- Repository. Таблица используется для хранения уже полученных репозиториев и краткой информации о них. Содержит следующие поля:
  - name -- название репозитория
  - namespace -- иначе groupId, в случае если проект -- библиотека из Maven
  - version -- версия
  - author -- автор
  - url -- локация репозитория, для GitHub это URL, а для Maven -- PURL
  - source -- источник, т.е. GitHub или Maven
  - path -- путь к проекту на используемой машине
  - date -- дата получения репозитория

- Trace. Данная таблица предназначена для хранения трасс и содержит в себе следующие поля:
  - trace -- трасса из вызовов в JSON формате. На самом деле подобное решение противоречит нормализации БД и является неоптимальным, можно сохранять методы в отдельную таблицу и хранить исключительно идентификаторы методов из неё. Но в рамках работы выбор сделан в пользу удобства просмотра накопленных трасс без средств обработки, а сравнительно малый объем данных в БД позволяет пренебречь нормальной формой
  - class -- класс, для которого собрана трасса
  - count -- количество найденных идентичных трасс
  - is_static -- флаг, демонстрирующий, содержит трасса статические вызовы или обычные. Так как в рамках предлагаемого подхода невозможно определить контекст статического вызова, было решено выделить их в отдельную трассу
  - extract_method -- каким методом была извлечена трасса

== Пакет inference

После извлечения и сохранения определенного количества трасс появляется возможность восстановить поведенческую модель библиотеки. Процесс восстановления происходит в несколько этапов:
+ Выбор трасс и их предобработка в соответствии с режимом работы. Это могут быть трассы, полученные только статическим или динамическим путем, а также статически полученные трассы, частично совпадающие с динамическими. При необходимости выполняется фильтрация трасс, которые будут использованы для восстановления
+ Формирование входного файла для фреймворка MINT, содержащего названия переходов и трассы
+ Применение алгоритма k-tail, реализованного в рамках MINT. Результатом является граф в DOT формате
+ Определение конечных состояний, т.е. таких, из которых отсутствуют любые переходы
+ Объединение конечных состояний. Для этого выбирается основное конечное состояние и у переходов, ведущих в остальные конечные состояния, подменяется точка назначения на основное. Лишние конечные состояния удаляются. Как уже было описано в разделе, посвященному проектированию, это действие не несет какой-либо потери информации
+ Трансляция DOT-графа в JSON для унификации формата хранения и возможной работы с ним (например, интерактивное редактирование). При этом DOT-граф остается в качестве артефакта работы инструмента

Для восстановления можно управлять параметром k, влияющим на длину минимально совпадающих частей трасс для слияния, а также выбирать другие предоставляемые mintframework стратегии восстановления и алгоритмы классификации.

== Реализованный инструмент

В результате разработан инструмент, реализующий подход автоматического извлечения поведенческих моделей библиотек из доступных программных репозиториев. В разработке учтена возможность использования модулей инструмента независимо друг от друга, а также предоставлены возможности настройки используемого окружения и библиотек. Исходный код проекта доступен в репозитории LibMiner#footnote("https://github.com/kechinvv/LibMiner") на GitHub.