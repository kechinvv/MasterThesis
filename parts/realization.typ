= Реализация

Создание инструмента для применения предложенного метода извлечения поведенческих моделей библиотек заключается в реализации каждой из его частей, разобранных ранее, и их связи между собой и пользователем. В данном разделе приведена общая архитектура инструмента и детали реализации его модулей, включая различные инженерные проблемы и пути их решения.  

== Общая архитектура

Реализованный инструмент может быть использован как консольное приложение или как библиотека, с помощью которой пользователь сможет реализовывать свои сценарии анализа или пользоваться отдельными её частями. Основой инструмента являются несколько пакетов:
+ analysis -- пакет, содержащий реализацию извлечения трасс с помощью статического и динамического анализа, а именно построение ICFG, points-to анализ, фаззинг и сбор точек входа в программу
+ inference -- пакет, обеспечивающий обработку трасс и восстановление из них поведенческих моделей
+ repository -- пакет, реализующий получение репозиториев и работу с ними
+ storage -- пакет, отвечающий за работу с БД
+ workflow -- пакет, связывающий все реализованные возможности между собой с помощью определенных сценариев работы

== Пакет repository

Данный пакет решает задачи поиска, получение и сборки проектов из GitHub и Maven Central Repository. Также в рамках этого пакета реализована возможность запуска тестов, имеющихся в репозитории. Рассмотрим каждую из задач подробнее.

=== Получение проектов с GitHub

Не смотря на то, что GitHub предоставляет открытый API для поиска по коду, при разработке возникли несколько проблем:
+ Поиск происходит по файлам, соответственно, сами репозитории могут повторяться. Необходимо это учитывать, чтобы не тратить лишнее время на получение и анализ уже рассмотренного ранее проекта.
+ Один поисковой запрос может найти не более 1000 результатов, что указано в документации#footnote("https://docs.github.com/en/rest/search/search?apiVersion=2022-11-28#about-search"). С учетом повторения репозиториев, этого может быть недостаточно для автоматической работы длительное время с целью изучить большое количество проектов. При этом сторонние системы поиска по коду, например SearchCode, имеют более сильные ограничения.
+ Частые запросы к API приводят к достижению secondary rate limit#footnote("https://docs.github.com/en/rest/using-the-rest-api/rate-limits-for-the-rest-api?apiVersion=2022-11-28#about-secondary-rate-limits"). При этом, основного лимита достаточно для выполнения запросов. Каким-то образом необходимо избежать введения искусственных задержек.

Для каждой из этих проблем были реализованы следующие решения:
+ Для исключения повторений следует хранить авторов и названия проанализированных репозитории в БД. Это также будет полезно для остановки и возобновлений поисковых сессий. Чтобы не обращаться каждый раз в БД для проверки репозитория на повторение, следует реализовать кэш.
+ Чтобы обойти лимит результатов поиска, реализован адаптивный фильтр по размеру файла. Способ фильтрации предлагает сам GitHub. Таким образом, мы можем задать диапазон от 0 до максимального размера файла, который нас интересует, и проходить его определенными шагами, например изначально 100 байт. Если количество результатов поиска находится между нулем и 1000, то не меняем шаг. Если количество результатов равно нулю, то мы увеличиваем шаг в два раза, а если максимальному значению -- уменьшаем шаг в два раза.
+ Во избежание secondary rate limit применяется ленивое получение репозиториев и их последовательный анализ, реализованное с помощью наследования Sequence в языке Kotlin. Каждый запрос к API возвращает набор файлов, из которых извлекаются уникальные репозитории, и до тех пор, пока все они не будут проанализированы, API использоваться не будет. Таким образом создается естественная задержка, позволяющая избегать лимита. Если он все же был достигнут (например, подряд выполнялись несколько уменьшений или увеличений размера шага), то используется sleep перед очередной попыткой запроса.

Для поиска и получения проектов с GitHub необходимо предварительно получить и указать свой токен для API в конфигурации инструмента, а на вход подать поисковой запрос и шаблон имени файла. Это необходимо, так как можно искать по импорту среди:
- .java файлов (path:\*\*\/\*.java)
- build.gradle (path:\*\*\/build.gradle)
- build.gradle.kts (path:\*\*\/build.gradle.kts или path:\*\*\/build.gradle\* для всех вариаций)
- pom.xml (path:\*\*\/pom.xml)

Для работы с удаленными GitHub репозиториями реализован класс GhRemoteRepository, позволяющий получать доступные артефакты и исходный код всего проекта:
+ Определяется наличие выпущенной версии
+ Проверяется наличие JAR файла соответствующего версии
+ Проверяется наличие исходного кода соответствующего версии
+ Если найдены, скачиваются JAR файл и архив с кодом версии, иначе выполняется клонирование с помощью git

=== Получение проектов с Maven Central

Веб-сайт Sonatype#footnote("https://central.sonatype.com/") предлагает возможность получения зависимых библиотек от выбранной. Однако публичного API для этого не предоставлено. С помощью инструментов разработчика в браузере было найдено внутреннее API, реализующее необходимую в рамках работы задачу. Способ нахождения и структура тела запроса представлена на @internal_api_struct. Чтобы исключить вероятность блокировки при использовании данного API, было направлено электронное письмо в поддержку Sonatype. В ответе говорилось, что допустимо использовать внутренний API, если нет намерений просканировать весь Maven Central, что в рамках выполняемой работы нас устраивает. 

#figure(
  image("../img/internal_api_structure.png", height: 23%),
  caption: "Поиск необходимого API"
) <internal_api_struct>

Для поиска проектов следует указать группу, название и версию библиотеки.

Получение найденных проектов осуществляется с помощью специально созданного build.gradle файла на одну зависимость, позволяющего подставлять в него библиотеку для анализа и выполнять задачу разрешения зависимостей. Таким образом происходит автоматическое получение и сборка библиотеки для анализа и всех её зависимостей. После разрешения зависимостей следует найти полученный JAR в кэше gradle и скопировать его в заданную директорию, где должны находиться анализируемые проекты.

Как уже было упомянуто в разделе, посвященному проектированию, получение исходного кода из Maven Central бессмысленно, так как он не содержит тестов, а сборка выполнена автоматически при получении проекта с помощью gradle.

=== Сборка проектов

Проекты из Maven Central собираются автоматически из-за выбранного метода их получения. Что касается проектов с GitHub, то даже при наличии JAR файла в репозитории, он может не содержать зависимости, а следовательно, он может не запуститься. Также необходима компиляция тестов, если они есть в проекте. 

Для этого требуется в первую очередь определить, какая система сборки используется в проекте. Это делается с помощью обхода файлов и поиска характерых файлов сборки: build.gradle, build.gradle.kts, pom.xml. Если ни один из файлов не обнаружен в корне проекта, то выполняется обход вложенных директорий, так как репозиторий может иметь нестандартные вложения или состоять из нескольких модулей.

Если проект использует Gradle, то вся работа с ним может быть выполнена с помощью Gradle Tooling API. В зависимости от конфигурации инструмента версия Gradle может быть установлена автоматически для каждого проекта, зафиксирована или может быть использован уже установленный на машине сборщик.

Maven не предполагает подобного API, поэтому в зависимости от конфигурации используется сборщик, к которому указан путь или из переменных окружения.

Все виды локальных репозиториев предусматривают методы сбора трасс из файлов, которые создаются в корне проекта как результат запуска инструментированного кода. Подробнее об этом в следующем подразделе.

== Пакет analysis

Данный пакет содержит реализацию статического анализа, инструментацию и запуск фаззинга, в совокупности предоставляя возможности для извлечения трасс вызовов библиотеки с применением статических и динамических подходов.

=== Сбор точек входа в программу

Как для статического извлечения трасс, так и для фаззинга необходимо предварительно получить возможные точки в программу. Помимо main метода, это могут быть:
- Обработчики событий. Например методы, отвечающие за обработку запросов
- Конструкторы
- Конкретные известные пользователю методы

Чтобы иметь гибкость вопросе выбора входных точек в программу, реализован механизм фильтрации для методов. Фильтры пишутся в YAML формате, в процессе работы инструмента десериализуются и используются для определения входных точек при обходе всех методов в программе. Фильтр содержит следующие поля:
+ methodAnnotation -- множество аннотаций метода, доступных в runtime
+ methodName -- регулярное выражение для названия метода
+ сlassAnnotation
+ className -- регулярное выражение для названия класса
+ kind -- вид метода, может быть модификатором доступа, конструктором (init) или статическим инициализатором (clinit)
+ args -- список типов аргументов метода в их оригинальном порядке

Если значения равны null, то параметр фильтра игнорируется. Пример фильтра для поиска публичных методов с названием, начинающимся на main, принимающих в себя массив строк, приведен на @filter_entry_example. 

#figure(
  ```yaml
methodTags: null
methodName: "main.*"
classTags: null
className: null
kind: "public"
args: ["java.lang.String[]"]```,
  caption: "Пример фильтра в yaml формате"
) <filter_entry_example>

=== Статическое извлечение трасс

Извлечение трасс с применением статического анализа состоит из нескольких основных шагов:
+ Получить точки входа в программу. Эта задача подробно разобрана чуть выше.
+ Построить ICFG. Решается использованием стандартного API Soot, однако построение межпроцедурного графа потока управления требует запуска Soot в режиме "whole-program".
+ Выполнить обход ICFG для каждой точки входа, собирая вызовы и группируя их посредством применения points-to анализа к объектам. Рассмотрим данную задачу отдельно, так как она требует разработки определенного алгоритма обхода.

Для обхода ICFG и выполнения всех необходимых для извлечения трассы действий следует реализовать SceneTransormer и добавить его PackageManager. Именно созданный SceneTransormer будет определять проводимый анализ.

ICFG представляет собой все возможные пути выполнения программы и, очевидно, в среднем содержит множество циклов и ветвлений. Так как нас интересуют именно трассы исполнения, их длинна может быть бесконечной и ее следует ограничивать. Для этого были введены два параметра:
- Глубина обхода. Изначально устанавливается некоторое число, которое уменьшается каждый раз, когда мы уходим в реализацию вызова. Когда глубина равна 0, обход не может попасть в реализацию какого-либо вызова в рассматриваемом методе и обязан пройти его до конца. Возвращаясь на уровень выше, глубина инкрементируется.
- Длина. Задает лимит по количеству вершин графа в рамках обхода.

При обходе перебираются все возможные в рамках наложенных ограничений по длине и глубине комбинации ветвлений. Благодаря этому возможно получение высокого покрытия кода и сбора содержательных трасс вызовов.

=== Динамическое извлечение трасс

== Пакет storage

== Пакет inference
