= Анализ решений в области восстановления поведенческих моделей

При изучении предметной области было выявлено, что на текущий момент нет исследований и инструментов, целью которых является полностью автоматизированный процесс получения спецификаций, начиная от получения проектов, использующих заданную библиотеку, и заканчивая извлечением из неё поведенческой модели. Тем не менее, в данной области достаточное количество работ, сосредоточенных на методах извлечения трасс и последующего восстановления модели библиотек, подразумевающих применение подходов к подготовленным для анализа программам. В данном разделе рассмотрены существующие способы извлечения трасс из программ и алгоритмы восстановления поведенческих моделей в виде КА и проведено их сравнение.

== Критерии сравнительного анализа

Выделим определенные критерии, на которые будем обращать внимание при обзоре работ.

=== Метод извлечения трасс

Глобально методы можно поделить на статические и динамические. Первые подразумевают анализ исходного кода или байт-кода программы без его запуска. Динамические методы, напротив, предполагают запуск анализируемой программы. Статические методы уступают в точности, однако позволяют покрыть все возможные пути исполнения программы. Эта особенность даёт возможность находить ошибки в тех участках кода, которые не покрыты тестами и до которых исполнение не доходит при штатной работе программы. Динамические методы, в свою очередь, за счет реального исполнения обеспечивают точность получаемых результатов, но с их помощью сложно получить все возможные состояния программы. Для восстановления поведенческой модели мы заинтересованы в получении как можно большего количества трасс, чему сопутствует использование статических методов, но в то же время ошибки в трассах неизбежно приведут к ошибкам в модели. Таким образом, недостатки одного метода являются преимуществом другого и наоборот. В работах нас интересует, как авторы реализовали преимущества и нивелировали недостатки выбранных методов.

=== Алгоритм восстановления модели

Алгоритм восстановления непосредственно влияет на качество получаемых моделей. При этом он определяет, какие данные необходимо извлечь из программы. Например, базовый алгоритм k-tail@ktail требует на вход исключительно последовательности вызовов и параметр k, отвечающий за длину хвостов, используемых для слияния состояний. Другой алгоритм, gk-tail@gktail, дополнительно требует на вход значения аргументов. 

Также существуют различные алгоритмы, основанные на использовании инвариантов или состояния программы в моменте вызова библиотеки. В рамках обзора важно обратить внимание, каких дополнительных усилий требует применение сложных алгоритмов восстановления, какие ограничения это накладывает и какой даёт прирост в точности и полноте получаемых автоматов.

Перед тем, как перейти к обзору современных работ, следует уделить особое внимание алгоритмам k-tail@ktail и gk-tail@gktail, на которых основано большинство современных методов восстановления автоматов из трасс. K-tail принимает на вход последовательность вызовов, полагая, что трасса -- это КА, где переходами являются вызовы. Для каждого состояния рассматриваются хвосты длиной k (обычно равной один или два) и если эти хвосты эквивалентны, то они сливаются. Безусловным плюсом данного алгоритма является высокая точность при простоте применения -- алгоритм не может породить модель, разрешающую несуществующие трассы, а также не требует дополнительной обработки входных данных. Но несмотря на то, что восстановленная модель описывает корректные последовательности, получаемые состояния КА не отражают реальные и являются грубой аппроксимацией реальной модели сверху.

Gk-tail основан на k-tail, однако помимо самих вызовов, также учитывает информацию об аргументах вызовов и контекстных переменных. Сначала трассы, состоящие из одинаковых вызовов, объединяются вместе с данными, накапливая множество возможных значений для переменных. Далее с помощью Daikon@daikona (используется в оригинальной статье, возможно использование других подобных инструментов) выполняется вывод инвариантов для каждого перехода, основанный на накопленных данных. Затем применяется алгоритм k-tail, однако для потенциально сливаемых хвостов происходит проверка инвариантов на конфликты. Данный алгоритм более трудозатратный ввиду необходимости получения информации о значении аргументов и контекстных переменных, а также обязательного вывода инвариантов. Но взамен достигается более осмысленное деление на состояния, чем при использовании K-tail.

=== Применимость к реальным проектам и возможность автоматизации

Определенные подходы могут показывать отличные результаты и иметь минимальные недостатки, но при этом иногда они совершенно не применимы к реальным проектам, что обусловлено либо новизной, либо фундаментальными ограничениями подхода. Также применение некоторых методов, в частности основанных на динамическом анализе, требует определенной ручной работы, например, связанной с подготовкой анализируемой программы и её окружения. Это может сильно влиять на массовость применения подхода и его автоматизацию.

=== Доступ к исходному коду

Если авторы предоставляют доступ к инструментам, это позволяет убедиться в результатах проведенных экспериментов. И, что не менее важно, появляется возможность применять и развивать разработанный в рамках исследований подход и инструмент.

== Обзор работ по извлечению спецификаций
    
В работе "Static Specification Mining Using Automata-Based Abstractions"@statmin авторы, используя абстрактную интерпретацию@abstractintr, статически собирают трассы в виде последовательностей объектов одного типа. Для получения последовательностей вызовов над конкретным экземпляром объекта в исследовании используется points-to анализ на основе алгоритма Андерсена@andersen (нечувствительный к потоку) и чувствительный к потоку access-paths анализ. При этом авторы не объединяют результаты применения анализов, а используют их в зависимости от потребности в максимально подробных и избыточных трассах (flow-insensitive) или точных и ограниченных (flow-sensitive). Для восстановления поведенческой модели авторы используют собственный подход, основанный на эвристических правилах слияния состояний. Предложенные алгоритмы выглядят интересно, однако сложно оценить их точность, так как в исследовании приводится сравнение результатов вариаций описанных алгоритмов между собой, хотя было бы уместно провести сравнение с классическим алгоритмом k-tail. В ограничениях подхода авторы описывают невозможность его применения для анализа проектов, состоящих из десятков тысяч строк кода. Это ожидаемо, поскольку flow-sensitive подходы сталкиваются с проблемой взрыва состояний и применение access-paths анализа к реальной программе требует большого количества памяти даже при минимальной глубине анализа@accesspath. Авторы делают вывод, что получаемые поведенческие модели достоверно описывают поведение библиотек, однако являются сильной аппроксимацией сверху истиной модели и содержат множество лишних состояний и переходов. Однако предполагается, что выявление чистых функций в исходном коде библиотеки позволит избежать появления избыточных состояний, так как на этапе восстановления будет известно, что определенные вызовы не изменяют состояния программы, а значит, конечную модель можно упростить. В статье явно упоминается разработанный инструментарий для проведения анализа, но ссылки на него не приводятся.

Авторы статьи "Automatic mining of specifications from invocation traces and method invariants"@medv подробно рассмотрели и сравнили четыре алгоритма восстановления моделей из трасс. При этом был рассмотрен базовый алгоритм k-tail, предложены улучшения для алгоритма Contractor@contractor, основанного на получении КА из инвариантов, а также разработаны новые подходы: SEKT и TEMI, заключающиеся в извлечении поведенческой модели из трасс, усиленных инвариантами, и инвариантов, усиленных трассами, соответственно. В рамках исследования авторы получали трассы и инварианты с помощью инструмента динамического анализа Daikon@daikona. Daikon -- очень мощный и полезный инструмент, однако его применение сложно автоматизировать для сторонних проектов, так как чтобы получить полные трассы и полезные инварианты из собственного целевого проекта, нужно проделать определенную нетривиальную работу. В статье очень большое внимание уделено сравнению методов восстановления КА. Авторы ввели метрики точности и полноты, где под точностью понимается доля трасс, сгенерированных по восстановленной модели и подходящих под эталонную модель, а полнота определяется как доля сгенерированных трасс по эталонной модели, не противоречащих восстановленной. В результате все методы, включая k-tail, показали точность близкую к 100 процентам для девяти эталонных моделей библиотек. Что касается полноты, k-tail и SEKT показали результат от 20% до 60%, имея примерно одинаковые значения в рамках конкретной библиотеки. TEMI и Contractor++ показали лучшие результаты, достигая значений 100% для некоторых библиотек, однако также сохранялся большой разброс и худшие результаты были на уровне 40%. Стоит заметить, что несмотря на очевидное преимущество более сложных алгоритмов, k-tail, требующий минимальные входные данные, показывает конкурентноспособный результат. В данном исследовании авторы не делятся реализацией алгоритмов, хоть и детально описывают принцип их работы. 

Интересный метод восстановления, а также его реализацию#footnote[https://github.com/neilwalkinshaw/mintframework] в открытом доступе предлагают  авторы статьи "Inferring Extended Finite State Machine models from software executions"@mint. Авторы развивают идею алгоритма gk-tail и предлагают использовать информацию о значении аргументов в анализируемых вызовов. Новизна заключается в том, что для поиска конфликтов слияния применяются обучаемые классификаторы. Под конфликтами понимаются слияния таких трасс, где из одного и того же состояния при одних и тех же вызовах осуществляется переход в отличные друг от друга состояния. Это говорит о том, что на самом деле начальное состояние было не одно и то же. В gk-tail поиск конфликтов между инвариантами происходит локально для отдельных участков трасс длиной k, из-за чего можно объединить состояния, где позже возникает конфликт. В предлагаемом подходе классификаторы используют трассы как источник данных для обучения, что позволяет осуществлять поиск конфликтов по всей совокупности данных. Также классификаторы избавляют от необходимости использовать тяжеловесные утилиты типа Daikon, неявно выполняя задачу вывода инвариантов. Благодаря одновременному учету всех трасс обеспечивается высокий уровень обобщенности получаемой поведенческой модели. Однако при этом на пользователя ложится задача подбора алгоритма для классификации данных, поскольку разные алгоритмы могут показывать разный результат в зависимости от входных данных. Авторы в своем исследовании приводят сравнение алгоритмов, а также предоставляют в реализованном инструменте возможность удобно его менять. Что касается получения трасс, в исследовании используются трассы полученные из двух проектов с помощью Daikon. Отдельно стоит поблагодарить авторов за реализацию алгоритмов k-tail и gk-tail в предоставляемом инструменте.

Ещё один выделяющийся подход реализован в инструментах Tautoko@tautoko для генерации тестов и ADABU@adabu, представленных в соответствующих исследованиях. ADABU решает задачу получения трасс и состояний программы на основе инструментации и реализует предложенный в исследовании метод восстановления поведенческой модели. Общий подход заключается в отслеживании состояния программы до и после вызова библиотеки. После сбора трасс, собранные состояния классифицируются по определенным правилам, тем самым образуя состояния КА. Tautoko же является генератором тестов, позволяющим получить ранее не обнаруженные варианты поведения библиотеки. Авторы предлагают реализованный подход как решение проблемы ограниченного набора тестов при использовании инструментов по типу Daikon. К сожалению, в исследованиях не представлены сравнения с существующими алгоритмами восстановления и инструментами генерации тестов. Однако представленных результатов достаточно, чтобы убедиться в работоспособности предложенных подходов, а наличие инструментов в открытом доступе#footnote[https://www.st.cs.uni-saarland.de/models/] делает полученные результаты очень полезными. Но важно отметить, что инструменты реализованы в 2012 году и не получали никаких обновлений. Скорее всего, они не актуальны для анализа современных версий Java. Также данный подход имеет ограничение в виде необходимости работы над конкретными проектами для извлечения трасс, так как требуется плотное взаимодействие с исполняемыми файлами анализируемого ПО.

== Результаты анализа

Все описанные работы предлагают работоспособные решения, подтверждаемые авторами в рамках проведенных экспериментов. Однако нигде не уделяется внимание автоматизации решения -- зачастую авторы извлекают трассы из одного и того же проекта (даже в рамках разных исследований разных авторов). Причиной этого является применение чисто динамических подходов для получения информации о состоянии программы в момент вызовов, что требует плотного взаимодействия с бинарными файлами программы и её необходимым окружением, а это довольно трудозатратно. Одна из описанных работ@statmin использует подход на основе статического анализа и имеет потенциал для автоматизации, однако авторы применяют чувствительный к потоку алгоритм для анализа псевдонимов, что делает подход неприменимым для реальных проектов. Краткий итог сравнения представлен в @table-cmp.

#figure(
  table(
    columns: 5,

    [Название], [Извлечение трасс], [Восстановление модели],  [Исх. код], [Ограничения],

    [Static Spec. Mining@statmin],  [Абстрактная интерпретация], [трассы], [Нет], [Невозможен анализ реальных проектов],

    [SEKT/TEMI@medv], [Daikon], [трассы,\ состояния], [Нет], [Частный подход к проектам], 

    [MINT@mint], [Daikon], [трассы,\ состояния], [Да], [Частный подход к проектам], 

    [Tautoko@tautoko/ADABU@adabu], [Собственная инструментация и генерация тестов], [трассы,\ состояния], [Да, \ устаревший], [Частный подход к проектам], 

    [Gk-tail], [Daikon], [трассы,\ состояния], [Да, в MINT], [Частный подход к проектам],  

    [K-tail], [-], [трассы], [Да, в MINT], [Получаемая модель далека от реальной],  
  ),
caption: [Анализ работ],
) <table-cmp>

Все это наводит на мысль о необходимости создания комплексного автоматизированного решения для извлечения трасс и поведенческих моделей библиотек. Безусловно, для начала автоматизация потребует некоторых уступков в требованиях к качеству получаемых автоматов и решения специфичных проблем. Но это положит начало развитию подобных автоматизированных методов и, возможно, позволит использовать извлечение автоматов в реальной жизни с меньшими усилиями.